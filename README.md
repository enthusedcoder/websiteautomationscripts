# My Website Automation Scripts

So I am what you might consider a "software hoarder": I browse Major Geeks on almost a daily basis, and if I see software that I like or think will be even remotely useful in some way, shape, or form, I download the executables and store them on my File server (this also is really helpful for when the developers of very useful software go out of business, decide not to share their product anymore, decide to start charging for their products in later releases of their software, etc.).  Some websites, however, simply have too much content to download manually, so rather than waste my time downloading all the software manually, I, you guessed it, wrote scripts to automate the process for me.  Launch any one of the scripts in this repository (sfk.exe is not a script, but a dependency), and it will automatically scrape the website specified in the script and download all of the executables (both installers and portable applications) for all of the software hosted on the sites.

## IMPORTANT

The powershell scripts and compiled executables (the files with the green download arrow icon) require powershell v3 at least to work properly.  The autoit scripts have no prerequisites.

